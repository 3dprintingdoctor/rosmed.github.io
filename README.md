# Building Software Systems for Image-Guided Robot-Assisted Interventions

## Date/Time
April 3, 2018, 1/2 day

## Organizers (affiliations and contact information):
- Junichi Tokuda, Brigham and Women’s Hospital and Harvard Medical School (tokuda@bwh.harvard.edu)
- Tamas Ungi, Queen’s University (ungi@queensu.ca)
- Axel Krieger, University of Maryland (axel@umd.edu)
- Simon Leonard, Johns Hopkins University (sleonard@jhu.edu)

## Objectives
The goal of this hands-on tutorial is to learn how to integrate medical image computing software into a system for image-guided robot-assisted interventions, in which 2D/3D medical images are used for planning, navigation, monitoring, and validation. Examples of such robot-assisted systems include image-guided robotic needle-guide systems and surgical CAD/CAM systems. Those systems often require a wide range of image computing features such as segmentation of anatomical structures, registration of multiple images, 2D/3D image visualization, image-based planning, and data sharing with the robot controller and the hospital’s picture archiving and communication systems (PACS). However, the engineering effort to implement those features is often ignored or underestimated in academic research due to limited engineering resources or the scope of the project. Fortunately, many of those features have already been implemented and validated by other researchers in the research community and often provided as open-source software toolkits. Therefore it has become essential for academic researchers to take advantage of those existing tools and incorporate them into their own research instead of reinventing the wheel. 
The session will consist of presentations by several experts in the field, followed by a hands-on tutorial. The presentations will overview the software systems for image-guided robot-assisted interventions with real-world use-cases in the context of academic research. In the tutorial session, the participants will build a system for image-guided robot-assisted interventions on their own laptop computers using popular research platforms for medical imaging and robotics, namely 3D Slicer and Robot Operating System (ROS). The two platforms will be seamlessly integrated using an open network communication protocol OpenIGTLink. Then the participant will build a demo system that allows a user to plan a procedure on a 3D image, execute the plan using a virtual robot, and visualize the feedback from the robot with the 3D image. At the end of the tutorial, the participants are expected to have a working demo system on their laptop, which could potentially be used as a template for their own research project.

## Topics of interest
- Image-guided interventions
- Navigation
- Open-source software
- Software-hardware integration
- Surgical CAD/CAM

## List of confirmed speakers
- Junichi Tokuda, Ph.D., Brigham and Women’s Hospital, Software System for Medical Robotics using 3D Slicer, OpenIGTLink and ROS
- Tamas Ungi, M.D., Ph.D., Queen’s University, Prototyping Software for Image-Guided Therapy
- Axel Krieger, Ph.D., University of Maryland, Software Systems for Autonomous Surgery
- Gregory Fischer, Ph.D., Worcester Polytechnic Institute
- Robert Webster, Ph.D., Vanderbilt University

## Time Table (TBD)
Presentation from invited speakers (~ 1 hour)
Hands-on tutorial session (~ 2 hours)

## Intended audience
Researchers, engineers, and students working in the field of medical robotics and image-guided interventions are welcomed to join. The tutorial would be particularly useful for those who are already engaged or will be engaged in the design, implementation, and clinical translation of a system for image-guided robot-assisted interventions. We strongly recommend the audience to bring their own laptop computers to follow the hands-on tutorial during the session. While the tutorial will not involve coding, some experience of running commands on a UNIX-like system and compiling open-source software using Make or CMake would be helpful.

## Expected attendance
10-30 people

